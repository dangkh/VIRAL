# VLIF
Pytorch implementation for "Enhancing Multimodal Recommendations with Vision-Language Models and Information-Aware Fusion" [arxiv](https://arxiv.org/pdf/.pdf)

```
VLIF/
│
├── data/
│   └── <dataset_name>/
│       ├── amazon_description_<dataset_name>_sample.json
│       ├── <dataset_name>_5.json
│       ├── <dataset_name>.inter
│       ├── i_id_mapping.csv
│       ├── meta_<dataset_name>.json
│       └── text_feat.npy         # Text embedding file generated by get_text_feat.py
│
├── src
│	├──get_text_feat.py              # Script to generate text embeddings
│	├──README.md
│   └─requirements.txt
```
## Usage

### 1. Install required libraries

```sh
conda create --name vlif python=3.10
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126C
pip install git+https://github.com/huggingface/transformers accelerate
pip install transformers accelerate timm einops bitsandbytes --quiet
pip install qwen-vl-utils[decord]==0.0.8
```

### 2. Generate text features for images

Vlm generate feature for image, edit src/config.py to change the dataset and vlm model.
```sh
python src/vlm2feat.py
```

Move the generated files to corresponding directory, name of generated file sample is: `amazon_baby_model_qwen_type_plain_descriptions.csv`

Place required files:
```
baby: gdown https://drive.google.com/uc?id=1_WKB112C095iHn8djsGCKYmhrdv0xtVS
```

Example with the "baby" dataset, using the "title" column to replace nan field:
```sh
python src/get_text_feat.py --dataset=baby --text_column=title
```

Arguments:
- `--dataset`: Name of the dataset (e.g., baby)
- `--text_column`: Name of the column containing text data (e.g., title)
- `--txt_embedding_model` (Not required): Name of the embedding model for text data (e.g., sentence-transformers/all-MiniLM-L6-v2)

The embedding file will be saved at: `data/<dataset_name>/en_image_feat.npy`


### 3. Training





This repo is implemented based on work of DRAGON: https://github.com/hongyurain/DRAGON



## Data
Data could be download from: [Baby/Sports/Clothing]()  

## The parameters to reproduce the result in our paper
| Datasets | learning rate | reg weight |
|----------|--------|---------|
| Baby     | 0.0001      | 0.001     |
| Sports   | 0.0001      | 0.001     |
| Clothing     | 0.0001      | 0.1     |

#### Please consider to cite our paper if this model helps you, thanks:
```
here
```
