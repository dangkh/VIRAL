# VLIF

```
VLIF/
│
├── data/
│   └── <dataset_name>/
│       ├── amazon_description_<dataset_name>_sample.json
│       ├── <dataset_name>_5.json
│       ├── <dataset_name>.inter
│       ├── i_id_mapping.csv
│       ├── meta_<dataset_name>.json
│       └── text_feat.npy         # Text embedding file generated by get_text_feat.py
│
├── src
│	├──get_text_feat.py              # Script to generate text embeddings
│	├──README.md
│   └─requirements.txt
```
## Usage

### 1. Install required libraries

```sh
conda create --name vlif python=3.10
pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126C
pip install git+https://github.com/huggingface/transformers accelerate
pip install transformers accelerate timm einops bitsandbytes --quiet
pip install qwen-vl-utils[decord]==0.0.8
```

### 2. Generate text features for images

Vlm generate feature for image, edit src/config.py to change the dataset and vlm model.
```sh
python src/vlm2feat.py
```

Move the generated files to corresponding directory, name of generated file sample is: `amazon_baby_model_qwen_type_plain_descriptions.csv`

Place required files:
```
baby: gdown https://drive.google.com/uc?id=1_WKB112C095iHn8djsGCKYmhrdv0xtVS
```

Example with the "baby" dataset, using the "title" column to replace nan field:
```sh
python src/get_text_feat.py --dataset=baby --text_column=title
```

Arguments:
- `--dataset`: Name of the dataset (e.g., baby)
- `--text_column`: Name of the column containing text data (e.g., title)
- `--txt_embedding_model` (Not required): Name of the embedding model for text data (e.g., sentence-transformers/all-MiniLM-L6-v2)

The embedding file will be saved at: `data/<dataset_name>/<text_column>_txt_feat.npy`
